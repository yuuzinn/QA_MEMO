> Login 과 Redisson Library를 사용하기 위해 Redis를 사용했다. <br>
> Login에는 Redis Session Storage를, Redisson Library에는 채팅방 동시성 이슈에 사용되었다.
### Redis Session Storage를 Login에 사용한 이유가 무엇인지?

- Tomcat Server에 문제가 생기더라도, 그에 따른 영향을 받지 않을 수 있다.
- 여러 Server Session 정보의 정합성을 유지할 수 있다.

### Redisson Library를 사용해서 어떻게 동시성 이슈를 해결한 건지?

- 채팅방의 고유 id 컬럼을 통해 Key로 설정해두고, 이를 통해 Lock을 획득하는 로직을 작성했으며<br>
일정 시간이 지나면 자동으로 Lock이 해제되게끔 leaseTime 매개변수를 통해 Custom하게 구현하였다.

### 그렇다면 그 외의 방법은 따로 없는지 고민해본 적이 있는지?

- DB Lock으로도 많이 고민했었다. 상황을 가정해, 해당 채팅방이 인기가 있을 것으로 생각하여 한번에 사람이 몰릴 것으로 생각했다.<br>
때문에 비관적 Lock을 통해서 강력하게 채팅방 입장 Lock을 잡고자 했다. 하지만 이의 방법은 DB I/O가 많이 일어나는 곳에선 오버 엔진이라 생각했다. 때문에 
빠르고 간단하게 해결할 수 있는 방법들을 찾다 보니, Redis를 알게 되었다.

### 비관적 Lock은 그럼 무엇인가?

- 비관적 Lock은 Race Condition이 일어날 것을 예상하여 미리 Lock을 걸어두는 방법론이다. 쓰기는 물론, 읽기도 Lock이 걸려 있기에 보통 돈과 관련된
강력한 Transaction이 필요한 곳에 사용할 것으로 생각한다.

### 연관관계 매핑을 통해 불필요한 쿼리를 어떻게 개선하였는지?

- N+1의 이슈를 직면하게 되었고, 이는 Fetch Join으로 해결했다. 또 다른 방법이 있을까 하여 찾아본 것이 Entity Graph였고, 
이를 통해서도 N+1를 해결한 적이 있다. Fetch Join을 통해 불필요한 쿼리는 나오지 않게 되었고, 쿼리 개수가 줄어듦에 따라 성능이 향상되었다.

### Entity Graph는 무엇인가?

- JPA에서 Fetch Join을 어노테이션으로 사용할 수 있게 도와주는 기능이다. 기능적으로는 Fetch Join과 동일하다.
- 연관관계를 LAZY를 걸어두어 쿼리 실행 시 Select 되지 않고, PROXY 객체를 만들어 Entity를 적용시킨다. 그 후 해당 Proxy 객체를 호출할 때마다 그때마다 Select 쿼리가 실행된다.

### N+1은 왜 나타나는지?

- JPA Fetch 전략으로 EAGER, LAZY 속성을 연관 Entity에 걸어두었을 때 발생한다.
  - EAGER는 불필요한 연관 Entity를 가져올 수 있는데, 그때 N+1이 발생할 수 있다.
  - LAZY는 필요할 때마다 Entity를 가져오게끔 처리하는 Proxy 객체가 있는데, 연관관계의 하위 Entity를 다시 조회할 경우 N+1가 발생할 수 있다.

- 따라서 Repository에서 select 할 때 첫 쿼리에서 하위 Entity까지 한 번에 가져오지 않고, 하위 Entity를 사용할 때 추가로 Select하기 때문에 발생하는 것이다.

### Message Queue의 Kafka, 다른 MQ도 있는데 왜 Kafka를 선택했는지?

- Kafka는 순차적인 disk I/O 방식을 통해 성능을 향상한다. 적은 비용으로도 많은 데이터를 유지하며,<br>
같은 Topic partition으로 보내진 메시지는 순서대로 처리됨을 보장받는다.<BR>
파티션을 나눌 경우, 순서가 보장되지 않기에 파티션을 그룹화하여 따로 처리해야만 순서를 보장받을 수 있다.
- RabbitMQ는 메시지 Consumer가 하나라면 순서를 보장하나, 그게 아니라면 순서를 보장하지 않는다.

채팅 도메인에 있어서 순서를 보장하는 것이 중요하다고 생각했기에 Kafka를 선택하게 되었다.

### Kafka Topic 생성에 관한 이슈가 있었다고 했는데, 자세히 이야기 해줄 수 있는지?

- 채팅방을 생성할 때마다 Kafka의 Topic을 하나씩 연결해서 데이터를 전달받을 수 있게끔 처리하고자 했다. <br>
생성할 때마다 Topic을 생성한다고 했을 때, 나중에 수 만개의 Topic이 있을 경우에도 성능이나 속도는 다를지에 대해 테스트해 본 결과, <br>
약 14만 정도의 Topic이 있을 때까지는 1개의 Topic 속도와 같았으며, 이를 넘어가면 조금씩 속도가 차이 나는 것을 볼 수 있었다.
- 프로젝트 상황을 가정해, 아직까진 유저의 수가 10만명도 안 될 뿐더러, 소규모로 진행했기에 Topic 생성을 채팅방마다 생성하기로 결정하였다.
- 여차하면 하나의 Topic 안에 파티션을 5개 정도씩 나누어 각각의 채팅방의 채팅 메시지를 넣을까도 고민했었다.

### Log 통계 계산 로직을 분리했다고 했는데, 어떻게 나눴는지 자세하게?

- 하루, 주간, 한 달 별로 손님이 어느 시간 대에 많이 왔는지 알아보고자 계산하는 로직을 작성했다. <br>
기존에는 DB쪽에서 먼저 평균값을 가지고 와서 Application 단에 넘겨주기만 했던 로직이었으나, 나중에 쿼리 개선 및 인덱스를 타기 위해 DB에서는 간단하게 Record들만 가져오게끔 처리했다.<br>
거기에서 가져온 값들을 Application단에서 계산하게끔 리팩토링을 진행했다.


### 문자 알림 서비스는 어떻게 제공했는지?

- 기존에는 Kakao에서 제공하는 카카오톡 API를 이용해 알림 서비스를 제공하려 했다.<BR>
하지만 손님들의 나이대와 사장님의 나이대를 고려해서 NEEDS에 맞게 문자 시스템으로 변경하게 되었다. <BR>
해당 문자 시스템은 Naver cloud에서 제공하는 API를 이용해 제공하고자 한다.

### REST API 규약을 준수한 URI 설계를 했다고 했는데, 어떻게 했는지 설명

- 조금 더 RESTFUL 하게 설계하고자 노력을 했다. 리소스에 대해서 어떻게 설계하면 좋을지 생각을 많이 했고,<br>
리소스별로 디렉토리를 나누는 것이 아닌 의미 있게 단수로 나누었다. 주로 LOG를 확인하는 API들의 위주로 GET 방식의 API를 많이 개발하게 되었다.
